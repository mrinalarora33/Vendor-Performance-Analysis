{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8abc78-dc53-4ae7-8fa3-417de819a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import time\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename = \"logs/ingestion_db.log\",\n",
    "    level = logging.DEBUG,\n",
    "    format = \"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode = \"a\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1279a1-8648-4b4e-add1-10fb46f3e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\HP\\Downloads\\data\n",
      "SQLite engine created for inventory.db\n",
      "Data directory set to: data\n",
      "Contents of 'data': ['.ipynb_checkpoints', 'begin_inventory.csv', 'end_inventory.csv', 'purchases.csv', 'purchase_prices.csv', 'sales.csv', 'vendor_invoice.csv']\n"
     ]
    }
   ],
   "source": [
    "# Show where the notebook is running\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Create SQLite engine (creates inventory.db in this folder if it doesn't exist)\n",
    "engine = create_engine(\"sqlite:///inventory.db\")\n",
    "print(\"SQLite engine created for inventory.db\")\n",
    "\n",
    "# Folder that contains your CSV files\n",
    "data_dir = \"data\"\n",
    "print(\"Data directory set to:\", data_dir)\n",
    "\n",
    "# Check that the folder exists and list files\n",
    "if os.path.isdir(data_dir):\n",
    "    print(f\"Contents of '{data_dir}':\", os.listdir(data_dir))\n",
    "else:\n",
    "    print(f\"WARNING: Directory '{data_dir}' does NOT exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29adc6e4-6191-44b7-99b6-2840c3020298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_db(csv_path: str, table_name: str, engine):\n",
    "    \"\"\"\n",
    "    Read a CSV in chunks and save to SQLite, splitting further\n",
    "    to avoid SQLite's 'too many SQL variables' limit, with minimal output.\n",
    "    \"\"\"\n",
    "    print(f\"Starting ingest for: {csv_path} -> table '{table_name}'\")\n",
    "\n",
    "    # Rows to read from CSV at a time (controls RAM usage)\n",
    "    read_chunksize = 50_000\n",
    "\n",
    "    # Stay below SQLite's default max variable limit (usually 999)\n",
    "    max_sql_variables = 900\n",
    "\n",
    "    first_write = True\n",
    "    total_rows = 0\n",
    "\n",
    "    # Read the CSV in chunks\n",
    "    for chunk in pd.read_csv(csv_path, chunksize=read_chunksize):\n",
    "        num_cols = len(chunk.columns)\n",
    "        # Max rows per batch so that rows * columns <= max_sql_variables\n",
    "        rows_per_batch = max(1, max_sql_variables // num_cols)\n",
    "\n",
    "        # Split the chunk into smaller batches and write each\n",
    "        for start in range(0, len(chunk), rows_per_batch):\n",
    "            batch = chunk.iloc[start:start + rows_per_batch]\n",
    "\n",
    "            batch.to_sql(\n",
    "                table_name,\n",
    "                engine,\n",
    "                if_exists=\"replace\" if first_write else \"append\",\n",
    "                index=False\n",
    "            )\n",
    "\n",
    "            first_write = False\n",
    "            total_rows += len(batch)\n",
    "\n",
    "    print(f\"Finished ingest for: {table_name} (total rows written: {total_rows})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3661f08f-5654-45bf-bed5-e0cb2eac646a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning data directory for CSV files...\n",
      "All files in data_dir: ['.ipynb_checkpoints', 'begin_inventory.csv', 'end_inventory.csv', 'purchases.csv', 'purchase_prices.csv', 'sales.csv', 'vendor_invoice.csv']\n",
      "\n",
      "--> Processing data\\begin_inventory.csv into table 'begin_inventory'\n",
      "Starting ingest for: data\\begin_inventory.csv -> table 'begin_inventory'\n",
      "Finished ingest for: begin_inventory (total rows written: 206529)\n",
      "\n",
      "--> Processing data\\end_inventory.csv into table 'end_inventory'\n",
      "Starting ingest for: data\\end_inventory.csv -> table 'end_inventory'\n",
      "Finished ingest for: end_inventory (total rows written: 224489)\n",
      "\n",
      "--> Processing data\\purchases.csv into table 'purchases'\n",
      "Starting ingest for: data\\purchases.csv -> table 'purchases'\n",
      "Finished ingest for: purchases (total rows written: 2372474)\n",
      "\n",
      "--> Processing data\\purchase_prices.csv into table 'purchase_prices'\n",
      "Starting ingest for: data\\purchase_prices.csv -> table 'purchase_prices'\n",
      "Finished ingest for: purchase_prices (total rows written: 12261)\n",
      "\n",
      "--> Processing data\\sales.csv into table 'sales'\n",
      "Starting ingest for: data\\sales.csv -> table 'sales'\n",
      "Finished ingest for: sales (total rows written: 12825363)\n",
      "\n",
      "--> Processing data\\vendor_invoice.csv into table 'vendor_invoice'\n",
      "Starting ingest for: data\\vendor_invoice.csv -> table 'vendor_invoice'\n",
      "Finished ingest for: vendor_invoice (total rows written: 5543)\n",
      "\n",
      "All matching CSV files have been ingested into inventory.db.\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data():\n",
    "    \"\"\"This function will load the CSVs and ingest them into the database.\"\"\"\n",
    "    data_dir = \"data\"\n",
    "\n",
    "    start = time.time()\n",
    "    logging.info(\"Scanning data directory '%s' for CSV files...\", data_dir)\n",
    "\n",
    "    if not os.path.isdir(data_dir):\n",
    "        logging.error(\"Directory '%s' does not exist. Fix data_dir or create the folder.\", data_dir)\n",
    "        return\n",
    "\n",
    "    files = os.listdir(data_dir)\n",
    "    logging.info(\"All files in '%s': %s\", data_dir, files)\n",
    "\n",
    "    processed_any = False\n",
    "\n",
    "    for file in files:\n",
    "        # Only handle CSV files\n",
    "        if file.lower().endswith(\".csv\"):\n",
    "            processed_any = True\n",
    "            csv_path = os.path.join(data_dir, file)\n",
    "            table_name = file[:-4]  # strip \".csv\" from filename\n",
    "\n",
    "            logging.info(\"Ingesting '%s' into db as table '%s'...\", file, table_name)\n",
    "\n",
    "            try:\n",
    "                ingest_db(csv_path, table_name, engine)\n",
    "            except PermissionError as e:\n",
    "                logging.warning(\n",
    "                    \"PermissionError while accessing '%s': %s. \"\n",
    "                    \"Tip: Close this file in Excel or any other program and rerun.\",\n",
    "                    csv_path,\n",
    "                    e\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # Log full stack trace for unexpected errors\n",
    "                logging.exception(\"Error while ingesting '%s': %s\", csv_path, e)\n",
    "\n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "\n",
    "    if not processed_any:\n",
    "        logging.warning(\"No CSV files found to process. Check filenames and filters.\")\n",
    "    else:\n",
    "        logging.info(\"-- Ingestion Complete --\")\n",
    "        logging.info(\"Total Time Taken: %.2f minutes\", total_time)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Main guard\n",
    "# -------------------------------------------------------------------\n",
    "if _name_ == \"_main_\":\n",
    "    load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f22e0-f957-4521-aee9-ec622de0dd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
